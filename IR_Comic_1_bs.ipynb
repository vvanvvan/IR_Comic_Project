{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IR_Comic_1_bs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 07610645 สราลี **ใจปัญญา**"
      ],
      "metadata": {
        "id": "Ep1-JprikOim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ระบบสืบค้น **Comic**"
      ],
      "metadata": {
        "id": "oAen6PgMdsUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "import library ในการดึงข้อมูลมาจากเว็บ\n",
        "\n",
        "*   BeautifulSoup ใช้ทำweb scraping\n",
        "*   requests ใช้อ่านหน้าเว็บ\n",
        "*   pandas ใช้saveเป็นcsv\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h1E1BVeQd06m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "kY0uX-_JWCJk"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#สร้างlist เพื่อเก็บข้อมูล\n",
        "\n",
        "names = []\n",
        "genres =[]\n",
        "synopsis = []\n",
        "original_language = []\n",
        "ratings = []"
      ],
      "metadata": {
        "id": "K6ihSp9lWEUj"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "กำหนด URL ที่ต้องการดึงข้อมูล ในที่นี้เราได้ทำการดึงมาจากเว็บ https://readm.org/popular-manga/rating"
      ],
      "metadata": {
        "id": "o9hMNV9SfLO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://readm.org/popular-manga/rating'\n",
        "response = requests.get(url)"
      ],
      "metadata": {
        "id": "2nuwSCLIfbxx"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ใช้ BeautifulSoup ดึง HTML content\n",
        "page_html = BeautifulSoup(response.text, 'html.parser')"
      ],
      "metadata": {
        "id": "CHTHGJi-fgCd"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ใส่tag ดึงข้อมูลที่ต้องการ\n",
        "comic_containers = page_html.find_all('li', class_='mb-lg')"
      ],
      "metadata": {
        "id": "30v1pj9dfiAE"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ข้อมูลที่จะดึงมาจากเว็บมี:\n",
        "\n",
        "1.   ชื่อของcomic\n",
        "2.   เรื่องย่อ\n",
        "3.   ประเภทหรือแนวของcomic\n",
        "4.   rating\n",
        "5.   ภาษาต้นฉบับของcomic\n",
        "\n",
        "โดยจะวนลูปเพื่อดึงข้อมูลมาจากHTML จากcodeด้านล่างจะดึงข้อมูลจากหน้าแรกก่อน เพราะลิ้งค์URLหน้าแรกไม่เหมือนหน้าที่2-9"
      ],
      "metadata": {
        "id": "8y7Oswilf37A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://readm.org/popular-manga/rating/'\n",
        "response = requests.get(url)\n",
        "\n",
        "for container in comic_containers:\n",
        "\n",
        "  # Scrape the name\n",
        "      name = container.find_next('h2', 'truncate').get_text(strip=True)\n",
        "      names.append(name)    \n",
        "      \n",
        "  # Scrape the synopsis\n",
        "      sp = container.find_next('p', 'desktop-only excerpt').get_text(strip=True)\n",
        "      synopsis.append(sp)\n",
        "      \n",
        "  # Scrape the original_language\n",
        "      original_lg = container.find('td').find_next_sibling('td').find('div').find_next_sibling('div').get_text(strip=True)\n",
        "      original_language.append(original_lg)\n",
        "\n",
        "  # Scrape the rating\n",
        "      rating = container.find('td').find_next_sibling('td').find_next_sibling('td').find_next_sibling('td').find('div','color-imdb').get_text(strip=True)\n",
        "      ratings.append(rating)\n",
        "      \n",
        "  # Scrape the genres \n",
        "      g = container.find_next('span','genres').get_text(strip=True)\n",
        "      genres.append(g) \n",
        "\n",
        "#เก็บข้อมูลในชุดข้อมูลที่กำหนด โดยจะเก็บในไฟล์.CSV\n",
        "comic_df = pd.DataFrame ({\n",
        "    'comic': names, \n",
        "    'synopsis' : synopsis,\n",
        "    'genre': genres,\n",
        "    'original_language' : original_language,\n",
        "    'rating' : ratings, \n",
        "})"
      ],
      "metadata": {
        "id": "ctDWyadAiyxR"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ต่อไปเราจะทำการดึงข้อมูลจากเว็บทั้งหมด 9 หน้า โดยใช้ลูปสองชั้น โดยลูปแรกจะวนตามจำนวนหน้าที่ต้องการดึงข้อมูล"
      ],
      "metadata": {
        "id": "Z3tEUMC1je3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#กำหนด URL ที่ต้องการดึงข้อมูล\n",
        "page_i = 2;\n",
        "for i in range(9):\n",
        " \n",
        "  url = 'https://readm.org/popular-manga/rating/'+str(page_i)\n",
        "  page_i+=1\n",
        "  response = requests.get(url)\n",
        "  #ใช้ BeautifulSoup ดึง HTML content\n",
        "  page_html = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "  #ดึงข้อมูลที่ต้องการ\n",
        "  comic_containers = page_html.find_all('li', class_='mb-lg')\n",
        "  \n",
        "  # printเพื่อดูจำนวนหน้า\n",
        "  print(url)\n",
        "\n",
        "  for container in comic_containers:\n",
        "\n",
        "  # Scrape the name\n",
        "      name = container.find_next('h2', 'truncate').get_text(strip=True)\n",
        "      names.append(name)    \n",
        "      \n",
        "  # Scrape the synopsis\n",
        "      sp = container.find_next('p', 'desktop-only excerpt').get_text(strip=True)\n",
        "      synopsis.append(sp)\n",
        "      \n",
        "  # Scrape the original_language\n",
        "      original_lg = container.find('td').find_next_sibling('td').find('div').find_next_sibling('div').get_text(strip=True)\n",
        "      original_language.append(original_lg)\n",
        "\n",
        "  # Scrape the rating\n",
        "      rating = container.find('td').find_next_sibling('td').find_next_sibling('td').find_next_sibling('td').find('div','color-imdb').get_text(strip=True)\n",
        "      ratings.append(rating)\n",
        "      \n",
        "  # Scrape the genres \n",
        "      g = container.find_next('span','genres').get_text(strip=True)\n",
        "      genres.append(g) \n",
        "\n",
        "#เก็บข้อมูลในชุดข้อมูลที่กำหนด โดยจะเก็บในไฟล์.CSV\n",
        "  comic_df = pd.DataFrame ({\n",
        "    'comic': names, \n",
        "    'synopsis' : synopsis,\n",
        "    'genre': genres,\n",
        "    'original_language' : original_language,\n",
        "    'rating' : ratings, \n",
        "    })\n",
        "\n",
        "\n",
        "  comic_df.to_csv('comic_data.csv')"
      ],
      "metadata": {
        "id": "l2pcxk8gWGWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "149dd133-5e05-4ab8-8437-f7a9601f071d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://readm.org/popular-manga/rating/2\n",
            "https://readm.org/popular-manga/rating/3\n",
            "https://readm.org/popular-manga/rating/4\n",
            "https://readm.org/popular-manga/rating/5\n",
            "https://readm.org/popular-manga/rating/6\n",
            "https://readm.org/popular-manga/rating/7\n",
            "https://readm.org/popular-manga/rating/8\n",
            "https://readm.org/popular-manga/rating/9\n",
            "https://readm.org/popular-manga/rating/10\n"
          ]
        }
      ]
    }
  ]
}